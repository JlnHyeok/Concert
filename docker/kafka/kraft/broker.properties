############################# 서버 기본 설정 #############################

# 이 서버의 역할. 이 설정은 KRaft 모드로 전환합니다.
process.roles=${KAFKA_PROCESS_ROLES:-broker}  # 환경변수로 설정, 기본값 broker

# 이 인스턴스의 역할과 관련된 노드 ID
node.id=${KAFKA_NODE_ID:-2}  # 환경변수로 설정, 기본값 2

# 컨트롤러 쿼럼 연결 문자열
controller.quorum.voters=${KAFKA_CONTROLLER_QUORUM_VOTERS:-1@localhost:9093}  # 환경변수로 설정, 기본값 1@localhost:9093

############################# 소켓 서버 설정 #############################

# 소켓 서버가 수신할 주소. 구성하지 않으면 호스트 이름은
# java.net.InetAddress.getCanonicalHostName()의 값이 사용되며,
# PLAINTEXT 리스너 이름과 포트 9092가 기본값으로 설정됩니다.
#   형식:
#     listeners = 리스너_이름://호스트_이름:포트
#   예시:
#     listeners = PLAINTEXT://your.host.name:9092
listeners=${KAFKA_LISTENERS:-PLAINTEXT://localhost:9092}  # 환경변수로 설정, 기본값 PLAINTEXT://localhost:9092

# 브로커 간 통신에 사용되는 리스너 이름
inter.broker.listener.name=${KAFKA_INTER_BROKER_LISTENER_NAME:-PLAINTEXT}  # 환경변수로 설정, 기본값 PLAINTEXT

# 클라이언트에게 브로커가 광고할 리스너 이름, 호스트 이름 및 포트.
# 설정하지 않으면 "listeners"의 값이 사용됩니다.
advertised.listeners=${KAFKA_ADVERTISED_LISTENERS:-PLAINTEXT://localhost:9092}  # 환경변수로 설정, 기본값 PLAINTEXT://localhost:9092

# 컨트롤러가 사용할 리스너 이름들의 쉼표로 구분된 목록.
# KRaft 모드에서는 필수입니다. `process.roles=broker`인 노드에서는 첫 번째 리스너만 브로커에서 사용됩니다.
controller.listener.names=${KAFKA_CONTROLLER_LISTENER_NAMES:-CONTROLLER}  # 환경변수로 설정, 기본값 CONTROLLER

# 리스너 이름을 보안 프로토콜에 매핑합니다. 기본값은 동일하게 설정됩니다. 더 자세한 내용은 구성 문서를 참조하세요.
listener.security.protocol.map=${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:-CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL}  # 환경변수로 설정

# 서버가 네트워크에서 요청을 수신하고 응답을 전송하는 데 사용하는 스레드 수
num.network.threads=${KAFKA_NUM_NETWORK_THREADS:-3}  # 환경변수로 설정, 기본값 3

# 서버가 요청을 처리하는 데 사용하는 스레드 수 (디스크 I/O 포함)
num.io.threads=${KAFKA_NUM_IO_THREADS:-8}  # 환경변수로 설정, 기본값 8

# 소켓 서버에서 사용하는 송신 버퍼(SO_SNDBUF)
socket.send.buffer.bytes=${KAFKA_SOCKET_SEND_BUFFER_BYTES:-102400}  # 환경변수로 설정, 기본값 102400

# 소켓 서버에서 사용하는 수신 버퍼(SO_RCVBUF)
socket.receive.buffer.bytes=${KAFKA_SOCKET_RECEIVE_BUFFER_BYTES:-102400}  # 환경변수로 설정, 기본값 102400

# 소켓 서버가 수락할 수 있는 요청의 최대 크기 (OOM 방지)
socket.request.max.bytes=${KAFKA_SOCKET_REQUEST_MAX_BYTES:-104857600}  # 환경변수로 설정, 기본값 104857600

############################# 로그 기본 설정 #############################

# 로그 파일을 저장할 디렉터리 목록 (쉼표로 구분)
log.dirs=${KAFKA_LOG_DIRS:-/tmp/kraft-broker-logs}  # 환경변수로 설정, 기본값 /tmp/kraft-broker-logs

# 기본 토픽당 로그 파티션 수. 더 많은 파티션은 소비에 대한 병렬성을 높이지만
# 브로커에 더 많은 파일을 생성하게 됩니다.
num.partitions=${KAFKA_NUM_PARTITIONS:-1}  # 환경변수로 설정, 기본값 1

# 시작 시 로그 복구 및 종료 시 플러싱에 사용되는 데이터 디렉터리당 스레드 수
num.recovery.threads.per.data.dir=${KAFKA_NUM_RECOVERY_THREADS_PER_DATA_DIR:-1}  # 환경변수로 설정, 기본값 1

############################# 내부 토픽 설정 #############################

# 그룹 메타데이터 내부 토픽 "__consumer_offsets" 및 "__transaction_state"의 복제 계수
offsets.topic.replication.factor=${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:-1}  # 환경변수로 설정, 기본값 1

# 트랜잭션 상태 로그 토픽의 복제 계수
transaction.state.log.replication.factor=${KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR:-1}  # 환경변수로 설정, 기본값 1

# 트랜잭션 상태 로그의 최소 ISR (In-Sync Replicas)
transaction.state.log.min.isr=${KAFKA_TRANSACTION_STATE_LOG_MIN_ISR:-1}  # 환경변수로 설정, 기본값 1

############################# 로그 플러시 정책 #############################

# 메시지는 즉시 파일 시스템에 기록되지만 기본적으로 OS 캐시를 지연시켜 fsync()를 호출합니다.
# 다음 설정은 디스크에 데이터를 플러시하는 방식을 제어합니다.
# 중요한 트레이드오프가 있습니다:
#    1. 내구성: 복제를 사용하지 않으면 플러시되지 않은 데이터가 손실될 수 있습니다.
#    2. 지연: 매우 긴 플러시 간격은 플러시 시 지연 스파이크를 일으킬 수 있습니다.
#    3. 처리량: 플러시는 가장 비싼 작업 중 하나이며, 짧은 플러시 간격은 과도한 탐색을 초래할 수 있습니다.
# 이 설정들은 데이터를 일정 시간 후 또는 N개의 메시지 후에 디스크에 플러시하도록 구성할 수 있습니다.

# 데이터를 디스크에 플러시하기 전 수락할 메시지 수
#log.flush.interval.messages=10000

# 메시지가 로그에 저장된 후 강제로 플러시하기까지 최대 시간
#log.flush.interval.ms=1000

############################# 로그 보존 정책 #############################

# 로그 세그먼트 처분을 제어하는 설정입니다. 정책은 시간 경과 후 또는 특정 크기까지 로그가 축적된 후 세그먼트를 삭제하도록 설정할 수 있습니다.
# 두 조건 중 하나라도 충족되면 세그먼트가 삭제됩니다. 삭제는 항상 로그의 끝에서 발생합니다.

# 로그 파일이 삭제되기 전에 최소 연령
log.retention.hours=${KAFKA_LOG_RETENTION_HOURS:-168}  # 환경변수로 설정, 기본값 168

# 로그의 크기 기반 보존 정책. 세그먼트는 log.retention.bytes 미만으로 떨어지지 않으면 삭제됩니다.
# log.retention.hours와 독립적으로 작동합니다.
#log.retention.bytes=1073741824

# 로그 세그먼트 파일의 최대 크기. 이 크기에 도달하면 새 로그 세그먼트가 생성됩니다.
log.segment.bytes=${KAFKA_LOG_SEGMENT_BYTES:-1073741824}  # 환경변수로 설정, 기본값 1073741824

# 로그 세그먼트가 보존 정책에 따라 삭제할 수 있는지 확인하는 간격
log.retention.check.interval.ms=${KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS:-300000}  # 환경변수로 설정, 기본값 300000
